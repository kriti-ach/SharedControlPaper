{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97147536",
   "metadata": {},
   "source": [
    "# Force Sensitive Data Processing\n",
    "\n",
    "This notebook processes data from the force-sensitive stopping task experiment.\n",
    "\n",
    "Running this notebook will:\n",
    "\n",
    "1. Load and process raw CSV data files from the experiment\n",
    "2. Calculate key metrics like Stop Signal Reaction Time (SSRT)\n",
    "3. Aggregate data across AI-assisted and Non-AI conditions\n",
    "4. Prepare the data for statistical analysis and visualization\n",
    "5. Save the processed data to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440fb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from sharedcontrolpaper.force_sensitive_stopping_task_utils import get_subject_label, aggregate_trial_data, process_trial_data, grab_mean_metric, find_sum_of_intervals, convert_dict_to_df, calculate_proportions_non_nan, collect_trial_metric, grab_mean_metric_by_halves, convert_formats, rename_index_column, convert_to_milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4170876",
   "metadata": {},
   "source": [
    "## Set up paths for data \n",
    "\n",
    "From the root of this project, the force sensitive stopping data lives `/data/experiment/final/sub-s*/force_sensitive_stopping_task`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076f4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 datafiles in /Users/kritiaxh/Documents/paperRepos/SharedControlPaper/data/experiment/final/sub-s*/force_sensitive_stopping_task/*.csv\n"
     ]
    }
   ],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(parent_directory, 'data', 'experiment')\n",
    "task = \"force_sensitive_stopping_task\"\n",
    "exp_stage = \"final\"\n",
    "pattern = os.path.join(data_path, exp_stage, 'sub-s*', task, '*.csv')\n",
    "data_files = glob(pattern)\n",
    "print(f\"Found {len(data_files)} datafiles in {pattern}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0887df9",
   "metadata": {},
   "source": [
    "## Derive task metrics from performance \n",
    "\n",
    "Loop through each subject, read in the dataframe, and get trials separated by block number. Then, aggregate these data to get measures for AI and Non-AI trial conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d377cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s042\n",
      "s029\n",
      "s016\n",
      "s011\n",
      "s018\n",
      "s027\n",
      "s020\n",
      "s043\n",
      "s021\n",
      "s019\n",
      "s026\n",
      "s010\n",
      "s028\n",
      "s017\n",
      "s035\n",
      "s032\n",
      "s004\n",
      "s005\n",
      "s033\n",
      "s034\n",
      "s012\n",
      "s015\n",
      "s023\n",
      "s024\n",
      "s041\n",
      "s025\n",
      "s022\n",
      "s014\n",
      "s013\n",
      "s040\n",
      "s031\n",
      "s036\n",
      "s009\n",
      "s007\n",
      "s038\n",
      "s006\n",
      "s039\n",
      "s037\n",
      "s008\n",
      "s030\n"
     ]
    }
   ],
   "source": [
    "shared_control_metrics = {}\n",
    "\n",
    "for file in data_files:\n",
    "    # Extract subject info and load data\n",
    "    subject_label = get_subject_label(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df['block'] = df['block'].str.strip(\"'\")\n",
    "    \n",
    "    # Filter out practice trials and split into blocks\n",
    "    df_test = df.query(\"block != 'practice'\")\n",
    "    blocks = {\n",
    "        'block 1': df_test.query(\"block == 'block 1'\").reset_index(drop=True),\n",
    "        'block 2': df_test.query(\"block == 'block 2'\").reset_index(drop=True)\n",
    "    }\n",
    "\n",
    "    # Process AI and non-AI data separately    \n",
    "    for block_df in blocks.values():\n",
    "        if 'AI-assisted' in block_df['condition'].values:\n",
    "            ai_data_agg = aggregate_trial_data(block_df.copy())\n",
    "        else:\n",
    "            non_ai_data_agg = aggregate_trial_data(block_df.copy())\n",
    "\n",
    "    # Store aggregated data\n",
    "    shared_control_metrics[subject_label] = {\n",
    "        'AI': {'data': ai_data_agg},\n",
    "        'Non-AI': {'data': non_ai_data_agg}\n",
    "    }\n",
    "\n",
    "    # Process trial results and SSRT for each condition\n",
    "    for condition in ['AI', 'Non-AI']:\n",
    "        condition_data = shared_control_metrics[subject_label][condition]['data']\n",
    "        trial_results, ssrt_list = process_trial_data(condition_data, block=condition)\n",
    "        \n",
    "        shared_control_metrics[subject_label][condition].update({\n",
    "            'trial_results': trial_results,\n",
    "            'ssrt_list': ssrt_list\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1444a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing metrics\n",
    "force_sensitive_stopping_task_ssrt = grab_mean_metric(shared_control_metrics, 'ssrt')\n",
    "duration_of_inhibition = grab_mean_metric(shared_control_metrics, 'duration_of_inhibition')\n",
    "\n",
    "# Accuracy metrics before and after stop signal\n",
    "go_task_accuracy_before_stop_onset = grab_mean_metric(shared_control_metrics, \n",
    "    'go_task_accuracy_before_stop_onset')\n",
    "go_task_accuracy_after_stop_onset = grab_mean_metric(shared_control_metrics,\n",
    "    'go_task_accuracy_after_stop_onset')\n",
    "\n",
    "# Ball and ring interaction metrics\n",
    "ball_after_ring_proportion_before_stop_onset = grab_mean_metric(shared_control_metrics,\n",
    "    'ball_after_ring_proportion_before_stop_onset')\n",
    "proportion_stops_before_stop_onset = grab_mean_metric(shared_control_metrics,\n",
    "    'proportion_stops_before_stop_onset')\n",
    "\n",
    "# Pressure timing metrics (aggregated across AI conditions)\n",
    "first_non_zero_pressure_timestamp = grab_mean_metric(shared_control_metrics,\n",
    "    'first_non_zero_pressure_timestamp', aggregate_ai=True)\n",
    "first_full_pressure_timestamp = grab_mean_metric(shared_control_metrics,\n",
    "    'first_full_pressure_timestamp', aggregate_ai=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0f46b",
   "metadata": {},
   "source": [
    "## Find proportion of full pressure points (pressure = 1) at each time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5689955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritiaxh/Documents/paperRepos/SharedControlPaper/src/sharedcontrolpaper/force_sensitive_stopping_task_utils.py:328: RuntimeWarning: invalid value encountered in divide\n",
      "  measures_dict[subject] = np.nansum(np.vstack(trials) == 1, axis=0) / counts # Count number of pressures=1\n"
     ]
    }
   ],
   "source": [
    "non_ai, ai_failed, ai_assisted = {}, {}, {}\n",
    "for subject, subject_data in shared_control_metrics.items():\n",
    "    results = collect_trial_metric(subject, subject_data, 'pressures_at_intervals_until_stop_onset')\n",
    "    # Find the maximum interval length to pad the lists to the same length\n",
    "    max_length = max(\n",
    "        max([len(lst) for lst in results['non_ai']], default=0),\n",
    "        max([len(lst) for lst in results['ai_failed']], default=0),\n",
    "        max([len(lst) for lst in results['ai_assisted']], default=0)\n",
    "    )\n",
    "            \n",
    "    non_ai = find_sum_of_intervals(results['non_ai'], non_ai, max_length, subject)\n",
    "    ai_failed = find_sum_of_intervals(results['ai_failed'], ai_failed, max_length, subject)\n",
    "    ai_assisted = find_sum_of_intervals(results['ai_assisted'], ai_assisted, max_length, subject)\n",
    "\n",
    "\n",
    "# Convert dictionaries into DataFrames for each condition\n",
    "time_intervals = [f\"{i * 100}-{(i + 1) * 100}ms\" for i in range(max_length)]\n",
    "\n",
    "non_ai_proportion_ones, ai_failed_proportion_ones, ai_assisted_proportion_ones = (\n",
    "    convert_dict_to_df(non_ai, time_intervals), \n",
    "    convert_dict_to_df(ai_failed, time_intervals), \n",
    "    convert_dict_to_df(ai_assisted, time_intervals)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c5fc4",
   "metadata": {},
   "source": [
    "## Finding the proportion of trials where subjects inhibited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3384f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_measure = {}\n",
    "proportion = {}\n",
    "\n",
    "for subject, subject_data in shared_control_metrics.items():\n",
    "    results = collect_trial_metric(subject, subject_data, 'ssrt')\n",
    "    counts, total_counts = calculate_proportions_non_nan(results)\n",
    "\n",
    "    proportion[subject] = {\n",
    "        'non_ai': counts['non_ai'] / total_counts['non_ai'] if total_counts['non_ai'] > 0 else 0,\n",
    "        'ai_failed': counts['ai_failed'] / total_counts['ai_failed'] if total_counts['ai_failed'] > 0 else 0,\n",
    "        'ai_assisted': counts['ai_assisted'] / total_counts['ai_assisted'] if total_counts['ai_assisted'] > 0 else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "df = pd.DataFrame(proportion).T\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd0677",
   "metadata": {},
   "source": [
    "## Create CSVs of SSRT by each half of trials in a block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d03f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssrt_first_half, ssrt_second_half = grab_mean_metric_by_halves(shared_control_metrics, 'ssrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632ccbd",
   "metadata": {},
   "source": [
    "## Store all data that will be written to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fed78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data formats and standardize column names\n",
    "converted_shared_control_metrics = convert_formats(shared_control_metrics)\n",
    "\n",
    "# Rename index column to subject_id\n",
    "for df in [force_sensitive_stopping_task_ssrt, duration_of_inhibition]:\n",
    "    rename_index_column(df)\n",
    "\n",
    "# Convert all time measurements to milliseconds\n",
    "time_measures = [\n",
    "    force_sensitive_stopping_task_ssrt,\n",
    "    duration_of_inhibition, \n",
    "    ssrt_first_half,\n",
    "    ssrt_second_half,\n",
    "    first_non_zero_pressure_timestamp,\n",
    "    first_full_pressure_timestamp\n",
    "]\n",
    "\n",
    "# Convert all time measurements to milliseconds\n",
    "for measure in time_measures:\n",
    "    convert_to_milliseconds(measure)\n",
    "\n",
    "# Group DataFrames that need to be converted to dictionaries\n",
    "dataframes_to_convert = {\n",
    "    'non_ai_proportion_ones': non_ai_proportion_ones,\n",
    "    'ai_failed_proportion_ones': ai_failed_proportion_ones, \n",
    "    'ai_assisted_proportion_ones': ai_assisted_proportion_ones,\n",
    "    'ssrt_first_half': ssrt_first_half,\n",
    "    'ssrt_second_half': ssrt_second_half,\n",
    "    'go_task_accuracy_after_stop_onset': go_task_accuracy_after_stop_onset,\n",
    "    'go_task_accuracy_before_stop_onset': go_task_accuracy_before_stop_onset,\n",
    "    'duration_of_inhibition': duration_of_inhibition,\n",
    "    'force_sensitive_stopping_task_ssrt': force_sensitive_stopping_task_ssrt,\n",
    "    'first_non_zero_pressure_timestamp': first_non_zero_pressure_timestamp,\n",
    "    'first_full_pressure_timestamp': first_full_pressure_timestamp\n",
    "}\n",
    "\n",
    "# Convert all DataFrames to dictionaries \n",
    "data_to_save = {\n",
    "    key: df.to_dict() for key, df in dataframes_to_convert.items()\n",
    "}\n",
    "\n",
    "# Add shared control metrics which is already a dictionary\n",
    "data_to_save['shared_control_metrics'] = converted_shared_control_metrics\n",
    "\n",
    "# Save data to JSON file so it can be read in by other notebooks\n",
    "with open('force_sensitive_data.json', 'w') as f:\n",
    "    json.dump(data_to_save, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
