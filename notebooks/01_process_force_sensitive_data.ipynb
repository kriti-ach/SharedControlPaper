{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76d7269-3905-4509-94bc-77e1cca385b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sharedcontrolpaper.force_sensitive_stopping_task_utils import get_subject_label, aggregate_trial_data, process_trial_data, find_sum_of_intervals, convert_dict_to_df, calculate_proportions_non_nan, collect_trial_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e8c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUSIONS = {\"s027\": [\"AI\", 80, 96]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb7faae-da47-461d-b5be-9eaa0074b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(parent_directory, 'data', 'experiment')\n",
    "task = \"force_sensitive_stopping_task\"\n",
    "exp_stage = \"final\"\n",
    "pattern = os.path.join(data_path, exp_stage, '*', task, '*.csv')\n",
    "data_files = glob.glob(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d185d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_control_metrics = {}\n",
    "for file in data_files:\n",
    "    subject_label = get_subject_label(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df['block'] = df['block'].str.strip(\"'\")\n",
    "    df_test = df.query(\"block != 'practice'\")\n",
    "    block_1 = df_test.query(\"block == 'block 1'\").reset_index(drop=True)\n",
    "    block_2 = df_test.query(\"block == 'block 2'\").reset_index(drop=True)\n",
    "\n",
    "    task_dfs = [block_1, block_2]\n",
    "\n",
    "    for df in task_dfs:\n",
    "        if 'AI-assisted' in df['condition'].values:\n",
    "            ai_data = df.copy()\n",
    "            ai_data_agg = aggregate_trial_data(ai_data)\n",
    "        else:\n",
    "            non_ai_data = df.copy()\n",
    "            non_ai_data_agg = aggregate_trial_data(non_ai_data)\n",
    "\n",
    "\n",
    "    shared_control_metrics[subject_label] = {'AI': {'data': ai_data_agg}, 'Non-AI': {'data': non_ai_data_agg}}\n",
    "\n",
    "    for block in shared_control_metrics[subject_label].keys():\n",
    "        trial_results, ssrt_list = process_trial_data(shared_control_metrics[subject_label][block]['data'], block=block)\n",
    "        shared_control_metrics[subject_label][block]['trial_results'] = trial_results\n",
    "        shared_control_metrics[subject_label][block]['ssrt_list'] = ssrt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5c6426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'shared_control_metrics' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store shared_control_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3e7cb",
   "metadata": {},
   "source": [
    "## Excluded Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77167a21-0510-4e0a-9670-eb5572056616",
   "metadata": {},
   "source": [
    "## Grabbing SSRT and other metrics across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb657879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_mean_metric(measure, aggregate_ai=False):\n",
    "    \"\"\"Calculates subject-level means for a specified metric.\"\"\"\n",
    "\n",
    "    condition_measure = {}\n",
    "    for subject, subject_data in shared_control_metrics.items():\n",
    "        #Check for exclusions, skip subject if needed\n",
    "        if subject in EXCLUSIONS and any(trial in EXCLUSIONS[subject] for block in subject_data for trial in subject_data[block]['trial_results']):\n",
    "            continue\n",
    "\n",
    "        results = collect_trial_metric(subject_data, measure, aggregate_ai)\n",
    "        condition_measure[subject] = {\n",
    "            'non_ai': np.nanmean(results['non_ai']),\n",
    "            'ai_failed': np.nanmean(results['ai_failed']),\n",
    "            'ai_assisted': np.nanmean(results['ai_assisted']),\n",
    "        }\n",
    "    return pd.DataFrame(condition_measure).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e319d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'force_sensitive_stopping_task_ssrt' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "force_sensitive_stopping_task_ssrt = grab_mean_metric('ssrt')\n",
    "%store force_sensitive_stopping_task_ssrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90eff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'duration_of_inhibition' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "duration_of_inhibition = grab_mean_metric('duration_of_inhibition')\n",
    "%store duration_of_inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00356be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'go_task_accuracy_before_stop_onset' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "go_task_accuracy_before_stop_onset = grab_mean_metric('go_task_accuracy_before_stop_onset')\n",
    "%store go_task_accuracy_before_stop_onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323393f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'go_task_accuracy_after_stop_onset' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "go_task_accuracy_after_stop_onset = grab_mean_metric('go_task_accuracy_after_stop_onset')\n",
    "%store go_task_accuracy_after_stop_onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12dfa308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_ai         0.000181\n",
      "ai_failed      0.000095\n",
      "ai_assisted    0.000241\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ball_after_ring_proportion_before_stop_onset = grab_mean_metric('ball_after_ring_proportion_before_stop_onset')\n",
    "print(ball_after_ring_proportion_before_stop_onset.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6b82af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_ai         0.051781\n",
      "ai_failed      0.050405\n",
      "ai_assisted    0.050405\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "first_non_zero_pressure_timestamp = grab_mean_metric('first_non_zero_pressure_timestamp', aggregate_ai=True)\n",
    "print(first_non_zero_pressure_timestamp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6af6579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_ai         0.179746\n",
      "ai_failed      0.148457\n",
      "ai_assisted    0.148457\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "first_full_pressure_timestamp = grab_mean_metric('first_full_pressure_timestamp', aggregate_ai=True)\n",
    "print(first_full_pressure_timestamp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e413399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_ai         0.026004\n",
      "ai_failed      0.022591\n",
      "ai_assisted    0.023667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "proportion_stops_before_stop_onset = grab_mean_metric('proportion_stops_before_stop_onset')\n",
    "print(proportion_stops_before_stop_onset.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9aa01",
   "metadata": {},
   "source": [
    "## Finding the proportion of full pressure points (pressure = 1) at each time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01db6408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritiaxh/Documents/paperRepos/SharedControlPaper/src/sharedcontrolpaper/force_sensitive_stopping_task_utils.py:310: RuntimeWarning: invalid value encountered in divide\n",
      "  measures_dict[subject] = np.nansum(np.vstack(trials) == 1, axis=0) / counts # Count number of pressures=1\n"
     ]
    }
   ],
   "source": [
    "non_ai, ai_failed, ai_assisted = {}, {}, {}\n",
    "for subject, subject_data in shared_control_metrics.items():\n",
    "    #Check for exclusions, skip subject if needed\n",
    "    if subject in EXCLUSIONS and any(trial in EXCLUSIONS[subject] for block in subject_data for trial in subject_data[block]['trial_results']):\n",
    "        continue\n",
    "\n",
    "    results = collect_trial_metric(subject_data, 'pressures_at_intervals_until_stop_onset')\n",
    "    # Find the maximum interval length to pad the lists to the same length\n",
    "    max_length = max(\n",
    "        max([len(lst) for lst in results['non_ai']], default=0),\n",
    "        max([len(lst) for lst in results['ai_failed']], default=0),\n",
    "        max([len(lst) for lst in results['ai_assisted']], default=0)\n",
    "    )\n",
    "            \n",
    "    non_ai = find_sum_of_intervals(results['non_ai'], non_ai, max_length, subject)\n",
    "    ai_failed = find_sum_of_intervals(results['ai_failed'], ai_failed, max_length, subject)\n",
    "    ai_assisted = find_sum_of_intervals(results['ai_assisted'], ai_assisted, max_length, subject)\n",
    "\n",
    "\n",
    "# Convert dictionaries into DataFrames for each condition\n",
    "time_intervals = [f\"{i * 100}-{(i + 1) * 100}ms\" for i in range(max_length)]\n",
    "\n",
    "non_ai_proportion_ones, ai_failed_proportion_ones, ai_assisted_proportion_ones = (convert_dict_to_df(non_ai, time_intervals), \n",
    "                                                           convert_dict_to_df(ai_failed, time_intervals), \n",
    "                                                           convert_dict_to_df(ai_assisted, time_intervals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac27c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'non_ai_proportion_ones' (DataFrame)\n",
      "Stored 'ai_failed_proportion_ones' (DataFrame)\n",
      "Stored 'ai_assisted_proportion_ones' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store non_ai_proportion_ones\n",
    "%store ai_failed_proportion_ones\n",
    "%store ai_assisted_proportion_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6e8f7",
   "metadata": {},
   "source": [
    "## Finding the proportion of trials where subjects inhibited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "479e0a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_ai         0.999744\n",
      "ai_failed      0.998718\n",
      "ai_assisted    0.991667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "condition_measure = {}\n",
    "proportion = {}\n",
    "\n",
    "for subject, subject_data in shared_control_metrics.items():\n",
    "    # Check for exclusions\n",
    "    if subject in EXCLUSIONS and any(trial in EXCLUSIONS[subject] for block in subject_data for trial in subject_data[block]['trial_results']):\n",
    "        continue\n",
    "\n",
    "    results = collect_trial_metric(subject_data, 'ssrt')\n",
    "    counts, total_counts = calculate_proportions_non_nan(results)\n",
    "\n",
    "\n",
    "    proportion[subject] = {\n",
    "        'non_ai': counts['non_ai'] / total_counts['non_ai'] if total_counts['non_ai'] > 0 else 0,\n",
    "        'ai_failed': counts['ai_failed'] / total_counts['ai_failed'] if total_counts['ai_failed'] > 0 else 0,\n",
    "        'ai_assisted': counts['ai_assisted'] / total_counts['ai_assisted'] if total_counts['ai_assisted'] > 0 else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "df = pd.DataFrame(proportion).T\n",
    "df = df.sort_index()\n",
    "print(df.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff2075",
   "metadata": {},
   "source": [
    "## Create CSVs of SSRT by each half of trials in a block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78161d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_mean_metric_by_halves(measure):\n",
    "    \"\"\"\n",
    "    Function to find the mean of a specified metric across different trial conditions \n",
    "    for each subject, split by halves of trials.\n",
    "\n",
    "    Parameters:\n",
    "    - measure (str): The name of the measure to calculate the mean for.\n",
    "\n",
    "    Outputs:\n",
    "    - Saves two CSV files with means for each subject across non_ai trials and ai condition trials\n",
    "      split by halves.\n",
    "    \"\"\"\n",
    "    # Initialize structures for data collection\n",
    "    condition_measure_first_half = {}\n",
    "    condition_measure_second_half = {}\n",
    "\n",
    "    for subject in shared_control_metrics.keys():\n",
    "        non_ai_first_half = []\n",
    "        non_ai_second_half = []\n",
    "        ai_failed_first_half = []\n",
    "        ai_failed_second_half = []\n",
    "        ai_assisted_first_half = []\n",
    "        ai_assisted_second_half = []\n",
    "        \n",
    "        for block in shared_control_metrics[subject].keys():\n",
    "            trial_results = shared_control_metrics[subject][block]['trial_results']\n",
    "            num_trials = len(trial_results)\n",
    "\n",
    "            for index, trial in enumerate(trial_results.keys()):\n",
    "                if subject in EXCLUSIONS.keys() and trial in EXCLUSIONS[subject] and block in EXCLUSIONS[subject]:\n",
    "                    continue\n",
    "                \n",
    "                ssrt_value = shared_control_metrics[subject][block]['trial_results'][trial][measure]\n",
    "                \n",
    "                if pd.isna(ssrt_value):\n",
    "                    continue\n",
    "                \n",
    "                if block == 'Non-AI':\n",
    "                    if index < num_trials / 2:  # First half\n",
    "                        non_ai_first_half.append(ssrt_value)\n",
    "                    else:  # Second half\n",
    "                        non_ai_second_half.append(ssrt_value)\n",
    "                    \n",
    "                elif block == 'AI':\n",
    "                    condition = shared_control_metrics[subject][block]['trial_results'][trial]['condition']\n",
    "                    if condition == 'AI-failed':\n",
    "                        if index < num_trials / 2:  # First half\n",
    "                            ai_failed_first_half.append(ssrt_value)\n",
    "                        else:  # Second half\n",
    "                            ai_failed_second_half.append(ssrt_value)\n",
    "                    elif condition == 'AI-assisted':\n",
    "                        if index < num_trials / 2:  # First half\n",
    "                            ai_assisted_first_half.append(ssrt_value)\n",
    "                        else:  # Second half\n",
    "                            ai_assisted_second_half.append(ssrt_value)\n",
    "                            \n",
    "        condition_measure_first_half[subject] = {\n",
    "            'non_ai': np.nanmean(non_ai_first_half),\n",
    "            'ai_failed': np.nanmean(ai_failed_first_half),\n",
    "            'ai_assisted': np.nanmean(ai_assisted_first_half)\n",
    "        }\n",
    "        \n",
    "        condition_measure_second_half[subject] = {\n",
    "            'non_ai': np.nanmean(non_ai_second_half),\n",
    "            'ai_failed': np.nanmean(ai_failed_second_half),\n",
    "            'ai_assisted': np.nanmean(ai_assisted_second_half)\n",
    "        }\n",
    "    \n",
    "    df_first_half = pd.DataFrame(condition_measure_first_half).T\n",
    "    df_second_half = pd.DataFrame(condition_measure_second_half).T\n",
    "\n",
    "    df_first_half = df_first_half.sort_index()\n",
    "\n",
    "    df_second_half = df_second_half.sort_index()\n",
    "    \n",
    "    return df_first_half, df_second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3e23021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ssrt_first_half' (DataFrame)\n",
      "Stored 'ssrt_second_half' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "ssrt_first_half, ssrt_second_half = grab_mean_metric_by_halves('ssrt')\n",
    "%store ssrt_first_half\n",
    "%store ssrt_second_half"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
